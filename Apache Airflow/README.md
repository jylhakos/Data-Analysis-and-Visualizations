# Apache Airflow

Apache Airflow is a platform that lets you build and run workflows. A workflow is represented as a DAG (a Directed Acyclic Graph), and contains individual pieces of work called Tasks, arranged with dependencies and data flows taken into account.

![alt text](https://github.com/jylhakos/Data-Analysis-and-Visualizations/blob/main/Apache%20Airflow/basic_airflow_architecture.png?raw=true)

*Figure: Apache Airflow usually operated and managed on a single machine*

Apache Airflow integrates machine learning workflows that involve tasks such as data preprocessing, feature engineering, model training, hyperparameter optimization, model assessment, and model deployment

### References

[Architecture Overview](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/overview.html)
